services:
  localai:
    image: localai/localai:latest-gpu-nvidia-cuda-12
    container_name: paperbanana_localai
    ports:
      - "8080:8080"
    environment:
      - MODELS_PATH=/build/models
      - THREADS=4
      # Enable CORS for local development if needed
      - CORS=true
      - CORS_ALLOW_ORIGINS=*
    volumes:
      - ./models:/build/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
    restart: unless-stopped
